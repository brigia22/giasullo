<!DOCTYPE html>
<html lang="en">
  
<head>
<style>

  a:link {color: black;text-decoration: none;
	border-bottom: 1px dashed black;}
a:visited {color: black;text-decoration: none;
	border-bottom: 1px dashed black;}
a:hover { color: black;text-decoration: none;
	border-bottom: 0px dashed;
	}
a:active {color: black;text-decoration: none;
	border-bottom: 0px dashed;}
  
body {
  background-image: url("background.jpg");
  background-attachment: fixed;
  padding-top: 10%;
  padding-right: 25%;
  padding-left: 10%;
  padding-bottom: 5%;
  background-color: lightsteelblue;
}
	
div.title {
font-family: gabriola,calibri,arial;
  text-align: center;
  font-size: 30px;
  color: black;
}
	
div.stuff {
font-family: calibri,arial;
  text-align: left;
  font-size: 18px;
  color: black;
}
		
  
</style>
</head>
  
<body>

 <div class="title">
	 <p>A Perfectionist's Take on Too-perfect Metadata</p>
   <p>April 30, 2020</p>
</div>

<div class="stuff">
  
  <p>I understand that probably the main purpose of metadata, and all of our learning and discussions in resource description, is interoperability -- meaning that if one repository describes an object a certain way, another repository should, theoretically, describe that same object in either the exact same way, or a way that is easily translatable (probably by a machine) into another repository’s database. In reality, we find that the process is way less simple than that. There are many types of metadata, all with varying options, and they all try to suit particular needs. Metadata for images, for archival records, for scientific data, for my personal diary, etc. etc. We all want everything to be described exactly the same way across all repositories and functions, so that, say, a doctor needs the medical history for a new patient: when the new patient’s medical history is sent over to the doctor, the same terms need to be used for the same things (controlled vocabulary) and the same ‘boxes’ need to be filled with the same data, so to speak. So for an example within an example, the data comes over and contains the patient’s date of birth: this can be formatted in various ways, such as YYYY-MM-DD or DD/MM/YY.</p>

<p>I think I’m getting too complex here and to make things simpler, say one library sends a book to another library via interlibrary loan. Each library uses a different system to track materials. The book comes over with metadata already previously filled, such as Title, Author, Summary, etc. But maybe the new library doesn’t have a Summary section in its database; instead it has a Synopsis, and so the Summary gets lost in the transfer, or goes into the wrong ‘box.’ Or say there is a Notes section that says, 'Please include this extra booklet with the DVD,' but the Notes section doesn’t transfer over and so the booklet is left behind. This actually happened to me once. I borrowed <i>Eraserhead</i> from the library and the DVD came with an interesting little booklet (which turned out to contain a really cool interview with David Lynch) rubber-banded to its case. The librarian got confused while retrieving the DVD because the booklet had not been documented in the DVD’s metadata record, and she thought it was a completely different material. She shook her head and said, 'Someone didn’t feel like doing their job.' I have an even funnier story, which I think I’ve previously mentioned, where someone placed a hold on <i>Pride and Prejudice</i>. When the person arrived to pick up the hold, the book she received was <i>Pride and Prejudice with Zombies</i>. This goofy error was probably due to a messed up metadata record.</p>

<p>Anyway, I had a different point: we are OBSESSED with perfection and machine-readability when it comes to metadata. But maybe we shouldn’t be. Maybe we should stop trying so hard to fight human error and variation in interpretation, and instead create metadata standards that allow or even encourage a little human-ness. I don’t know what that would look like just yet, but I have to think about accounting: in probably every organization, accountants track human errors in their books. They have special accounting codes and procedures for dealing with all types of human errors. The billion dollar corporation that I worked for before my current job had what was called a ‘suspense account’ built-in for payments that we received but had no idea where they belonged. We just plopped payments into this account until we figured out where they really belonged. We had $500 from Disney sitting in that account for months; for all I know it’s still there, and Disney is surely not missing it. But even detail-crazed, persnickety accountants need to have built-in systems to record mistakes and straight-up mysteries. In my current job, half the monthly close consists of writing journal entries which are essentially Excel spreadsheets that document mistakes or discrepancies and provide backup to explain what happened. I think metadata attempts to replicate this with things called Notes sections, or by allowing librarians to take educated guesses when they don’t know the exact dates for particular materials. But maybe we should implement more measures like this, ones that address human error and interpretation.</p>

<p>It’s true that automation has done away with a lot of human error. But even when using machines to automatically generate metadata, there are oftentimes enough mistakes that a pretty standard practice is to have humans go in and double-check the work of the machines. Even as I type this, Google is trying to correct my grammar and I have to tell it that it’s wrong! Artificial intelligence and machine-reading have certainly come a long way. But humans are, at least for now, still the ones in control. My grammar may not be perfect by Google’s standards, but unlike a machine I have the ability to decide whether I want to use potentially incorrect grammar on purpose. I can’t help but think that language and metadata kind of need those little human discrepancies in order to evolve.</p>

<br>
  
	</div>
</body>
</html>
